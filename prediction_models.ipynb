{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-813a7e1e1360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mlou_cross_validation_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mlou_cross_validation_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mlou_cross_validation_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-813a7e1e1360>\u001b[0m in \u001b[0;36mlou_cross_validation_audio\u001b[0;34m(audio_path, save_results)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginalname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovedname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatureAndTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/lie\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/truth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortTermWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortTermStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"svm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"audio_models/svm/svm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovedname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"audio_models/svm/svm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"svm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_label_by_story\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pyAudioAnalysis import audioTrainTest as aT\n",
    "\n",
    "labels = pd.read_csv(\"project_data/labels.csv\", usecols=[0,1], dtype={\"id\": int, \"label\": str}, index_col=0)\n",
    "\n",
    "audio_results = \"audio_predictions/\"\n",
    "def get_label_by_story(subject, story):\n",
    "    return labels.loc[subject].values[0][story-1]\n",
    "\n",
    "def lou_cross_validation_audio(audio_path, save_results=None):\n",
    "    save_results = audio_path if save_results==None else save_results\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(audio_path):\n",
    "        for f in files:\n",
    "            all_files.append(os.path.join(root, f))\n",
    "    predictions = {}\n",
    "    for trfile in all_files:\n",
    "        originalname = trfile\n",
    "        inter = originalname.split(\"/\")[-1].strip(\"sub\").strip(\".wav\").split(\"_\")\n",
    "        sub, st = int(inter[0]), int(inter[1])\n",
    "        movedname = originalname.replace(originalname.split(\"/\")[1], \"fold\")\n",
    "        os.rename(originalname, movedname)\n",
    "        aT.featureAndTrain([audio_path + \"/lie\", audio_path + \"/truth\"], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"svm\", \"audio_models/svm/svm\", True)\n",
    "        prediction = aT.fileClassification(movedname, \"audio_models/svm/svm\", \"svm\")[1][1]\n",
    "        prediction = 1 if prediction>0.5 else 0\n",
    "        predictions[(sub, st)] = [prediction, get_label_by_story(sub, st)]\n",
    "        os.rename(movedname, originalname)\n",
    "\n",
    "    with open(audio_results + save_results + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(predictions, f)\n",
    "\n",
    "control_group = \"audio_control_group\"\n",
    "test_group = \"audio_test_group\"\n",
    "complete_group = \"audio_complete_group\"\n",
    "lou_cross_validation_audio(control_group)\n",
    "lou_cross_validation_audio(test_group)\n",
    "lou_cross_validation_audio(complete_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate of audio_control_group: 77.7778%\n",
      "Correct classification rate of audio_test_group: 72.7273%\n",
      "Correct classification rate of audio_complete_group: 62.3188%\n",
      "\n",
      "Correct classification rate of knn_control: 27.7778%\n",
      "Correct classification rate of knn_test: 26.6667%\n",
      "Correct classification rate of knn_complete: 28.7879%\n",
      "Correct classification rate of lc_control: 38.8889%\n",
      "Correct classification rate of lc_test: 46.6667%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def deserialize(f):\n",
    "    with open(f, \"rb\") as ser:\n",
    "        return pickle.load(ser)\n",
    "\n",
    "\n",
    "def evaluate_predictions(root):\n",
    "    for root, dirs, files in os.walk(root):\n",
    "        for f in files:\n",
    "            predictions = deserialize(os.path.join(root, f))\n",
    "            results = np.array(predictions.values()).astype(int)\n",
    "        #     results mse(results[:, 0], results[:, 1])\n",
    "#             results = results[results[:,1]==0]\n",
    "#             print results\n",
    "            \n",
    "            results = results[:, 0] - results[:, 1]\n",
    "            results = (len(results) - sum(abs(results)))/float(len(results))\n",
    "            f = f.split(\".\")[0]\n",
    "            print \"Correct classification rate of {}: {:.4f}%\".format(f, results*100)\n",
    "\n",
    "evaluate_predictions(\"audio_predictions\")\n",
    "print\n",
    "evaluate_predictions(\"thermal_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermal model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "thermal_predictions = \"thermal_predictions/\"\n",
    "\n",
    "def deserialize(f):\n",
    "    with open(f, \"rb\") as ser:\n",
    "        return pickle.load(ser)\n",
    "\n",
    "def cross_validate(data, fname, method='knn'):\n",
    "    preds = {}\n",
    "    for key in data.keys():\n",
    "        test = (key, data[key])\n",
    "        del data[key]\n",
    "        train = np.vstack(data.values())\n",
    "        nclass.fit(np.vstack(train[:,0]), train[:,1].astype(int))\n",
    "        knnpred = nclass.predict(np.vstack(test[1][:,0]))\n",
    "        truth, lie = sum(knnpred), len(knnpred)-sum(knnpred)\n",
    "        p = 1 if truth > lie else 0\n",
    "        preds[key] = [p, test[1][0][1]]\n",
    "        data[key] = test[1]\n",
    "    with open(os.path.join(thermal_predictions, method, method + \"_\" + fname+\".pickle\"), \"wb\") as f:\n",
    "        pickle.dump(preds, f)\n",
    "\n",
    "complete_group = {}\n",
    "control_group = deserialize(\"thermal_data/control_group.pickle\")\n",
    "test_group = deserialize(\"thermal_data/test_group.pickle\")\n",
    "complete_group.update(control_group)\n",
    "complete_group.update(test_group)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
