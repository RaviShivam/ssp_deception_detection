{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-813a7e1e1360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mlou_cross_validation_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mlou_cross_validation_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mlou_cross_validation_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-813a7e1e1360>\u001b[0m in \u001b[0;36mlou_cross_validation_audio\u001b[0;34m(audio_path, save_results)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginalname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovedname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatureAndTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/lie\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/truth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortTermWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortTermStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"svm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"audio_models/svm/svm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovedname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"audio_models/svm/svm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"svm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_label_by_story\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pyAudioAnalysis import audioTrainTest as aT\n",
    "\n",
    "labels = pd.read_csv(\"project_data/labels.csv\", usecols=[0,1], dtype={\"id\": int, \"label\": str}, index_col=0)\n",
    "\n",
    "audio_results = \"audio_predictions/\"\n",
    "def get_label_by_story(subject, story):\n",
    "    return labels.loc[subject].values[0][story-1]\n",
    "\n",
    "def lou_cross_validation_audio(audio_path, save_results=None):\n",
    "    save_results = audio_path if save_results==None else save_results\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(audio_path):\n",
    "        for f in files:\n",
    "            all_files.append(os.path.join(root, f))\n",
    "    predictions = {}\n",
    "    for trfile in all_files:\n",
    "        originalname = trfile\n",
    "        inter = originalname.split(\"/\")[-1].strip(\"sub\").strip(\".wav\").split(\"_\")\n",
    "        sub, st = int(inter[0]), int(inter[1])\n",
    "        movedname = originalname.replace(originalname.split(\"/\")[1], \"fold\")\n",
    "        os.rename(originalname, movedname)\n",
    "        aT.featureAndTrain([audio_path + \"/lie\", audio_path + \"/truth\"], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"svm\", \"audio_models/svm/svm\", True)\n",
    "        prediction = aT.fileClassification(movedname, \"audio_models/svm/svm\", \"svm\")[1][1]\n",
    "        prediction = 1 if prediction>0.5 else 0\n",
    "        predictions[(sub, st)] = [prediction, get_label_by_story(sub, st)]\n",
    "        os.rename(movedname, originalname)\n",
    "\n",
    "    with open(audio_results + save_results + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(predictions, f)\n",
    "\n",
    "control_group = \"audio_control_group\"\n",
    "test_group = \"audio_test_group\"\n",
    "complete_group = \"audio_complete_group\"\n",
    "lou_cross_validation_audio(control_group)\n",
    "lou_cross_validation_audio(test_group)\n",
    "lou_cross_validation_audio(complete_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate of audio_control_group: 77.7778%\n",
      "Correct classification rate of audio_test_group: 72.7273%\n",
      "Correct classification rate of audio_complete_group: 62.3188%\n",
      "\n",
      "Correct classification rate of knn_control: 27.7778%\n",
      "Correct classification rate of knn_test: 26.6667%\n",
      "Correct classification rate of knn_complete: 28.7879%\n",
      "Correct classification rate of svm_control: 61.1111%\n",
      "Correct classification rate of svm_test: 66.6667%\n",
      "Correct classification rate of lc_control: 38.8889%\n",
      "Correct classification rate of lc_complete: 42.4242%\n",
      "Correct classification rate of lc_test: 46.6667%\n",
      "Correct classification rate of base_diff_test: 66.6667%\n",
      "Correct classification rate of base_diff_control: 55.5556%\n",
      "Correct classification rate of base_diff_complete: 60.6061%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def deserialize(f):\n",
    "    with open(f, \"rb\") as ser:\n",
    "        return pickle.load(ser)\n",
    "\n",
    "\n",
    "def evaluate_predictions(root):\n",
    "    for root, dirs, files in os.walk(root):\n",
    "        for f in files:\n",
    "            predictions = deserialize(os.path.join(root, f))\n",
    "            results = np.array(predictions.values()).astype(int)\n",
    "        #     results mse(results[:, 0], results[:, 1])\n",
    "#             results = results[results[:,1]==0]\n",
    "#             print results\n",
    "            \n",
    "            results = results[:, 0] - results[:, 1]\n",
    "            results = (len(results) - sum(abs(results)))/float(len(results))\n",
    "            f = f.split(\".\")[0]\n",
    "            print \"Correct classification rate of {}: {:.4f}%\".format(f, results*100)\n",
    "\n",
    "evaluate_predictions(\"audio_predictions\")\n",
    "print\n",
    "evaluate_predictions(\"thermal_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermal model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "thermal_predictions = \"thermal_predictions/\"\n",
    "label_folder = \"project_data/labels.csv\"\n",
    "game = pd.read_csv(label_folder, usecols=[0,3], dtype={\"id\": int, \"game\": int})\n",
    "game = game.drop([0,1,3]).values\n",
    "test = game[game[:,1]==1]\n",
    "control = game[game[:,1]==0]\n",
    "\n",
    "def deserialize(f):\n",
    "    with open(f, \"rb\") as ser:\n",
    "        return pickle.load(ser)\n",
    "\n",
    "baseline = deserialize(\"thermal_data/baseline.pickle\")\n",
    "\n",
    "def mean_predict(data, from_subj, fname, method='base_diff'):\n",
    "    preds = {}\n",
    "    for subject, game in from_subj:\n",
    "        sub_base = baseline[subject]\n",
    "        st1 = np.vstack(np.vstack(data[(subject, 1)])[:,0]) - sub_base\n",
    "        st2 = np.vstack(np.vstack(data[(subject, 2)])[:,0]) - sub_base\n",
    "        st3 = np.vstack(np.vstack(data[(subject, 3)])[:,0]) - sub_base\n",
    "        st1, st2, st3 = sum(st1)/len(st1), sum(st2)/len(st2), sum(st3)/len(st3)\n",
    "        st1, st2, st3 = [1, np.sqrt(st1.dot(st1))], [2, np.sqrt(st2.dot(st2))], [3, np.sqrt(st3.dot(st3))]\n",
    "        strs = np.vstack((st1, st2, st3))\n",
    "        lie = np.where(strs == np.max(strs[:,1]))[0][0]\n",
    "        for i in range(1,4):\n",
    "            p = 0 if(i==lie) else 1\n",
    "            preds[(subject, i)] = [p, data[(subject, i)][0][1]]\n",
    "        \n",
    "    with open(os.path.join(thermal_predictions, method, method + \"_\" + fname+\".pickle\"), \"wb\") as f:\n",
    "        pickle.dump(preds, f)\n",
    "        \n",
    "#     for key in data.keys():\n",
    "#         test = (key, data[key])\n",
    "#         del data[key]\n",
    "#         train = np.vstack(data.values())\n",
    "#         nclass.fit(np.vstack(train[:,0]), train[:,1].astype(int))\n",
    "#         knnpred = nclass.predict(np.vstack(test[1][:,0]))\n",
    "#         truth, lie = sum(knnpred), len(knnpred)-sum(knnpred)\n",
    "#         p = 1 if truth > lie else 0\n",
    "#         preds[key] = [p, test[1][0][1]]\n",
    "#         data[key] = test[1]\n",
    "\n",
    "complete_group = {}\n",
    "control_group = deserialize(\"thermal_data/control_group.pickle\")\n",
    "test_group = deserialize(\"thermal_data/test_group.pickle\")\n",
    "complete_group.update(control_group)\n",
    "complete_group.update(test_group)\n",
    "mean_predict(control_group, control, 'control')\n",
    "mean_predict(test_group, test, 'test')\n",
    "mean_predict(complete_group, game, 'complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.35994902  0.25926232  5.49662478  4.35322393  4.20367802]\n",
      " [ 3.30334821  2.04648634  6.19270966  2.99654674  2.66827275]\n",
      " [ 6.21133833  5.29142094  1.34579945  5.13578121  1.84439866]\n",
      " [ 7.85335148  8.53975293  4.94236837  8.46561485  0.79645477]\n",
      " [ 5.0524609   0.65286504  4.28122328  0.96530916  1.27159972]\n",
      " [ 5.96745309  2.26012001  1.06945684  2.20306207  3.49826285]\n",
      " [ 4.67787485  2.01743226  6.40406725  4.83069836  5.0523672 ]\n",
      " [ 3.86892651  7.93637454  5.80004179  1.62298599  7.00752347]\n",
      " [ 9.6455108   5.00008361  8.89520064  3.41613653  5.67144128]\n",
      " [ 4.27545963  4.36747263  7.76559185  5.35604173  9.53742227]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([8]), array([0]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "x = np.vstack(10*np.array(np.random.random((10, 5))))\n",
    "print x\n",
    "y = np.array(range(1,6))\n",
    "np.where(x == np.max(x))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
